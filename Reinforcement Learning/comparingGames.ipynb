{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game1 = gym.make('FrozenLake-v0')\n",
    "\n",
    "game2 = gym.make('Taxi-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game1_action_size = game1.action_space.n\n",
    "game1_state_size = game1.observation_space.n\n",
    "\n",
    "game2_action_size = game2.action_space.n\n",
    "game2_state_size = game2.observation_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game1_qtable = np.zeros((game1_state_size, game1_action_size))\n",
    "print(game1_qtable.shape)\n",
    "\n",
    "game2_qtable = np.zeros((game2_state_size, game2_action_size))\n",
    "print(game2_qtable.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_episodes = [10000, 15000, 20000, 25000] \n",
    "learning_rate = 0.9\n",
    "max_steps = 99\n",
    "gamma = 0.95\n",
    "\n",
    "epsilon = 1.0\n",
    "max_epsilon = 1.0\n",
    "min_epsilon = 0.01\n",
    "decay_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing different parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of episodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Game 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Game 1\n",
    "total_episodes = [10000, 15000, 20000, 25000]\n",
    "learning_rate = 0.9\n",
    "max_steps = 99\n",
    "gamma = 0.95\n",
    "\n",
    "epsilon = 1.0\n",
    "max_epsilon = 1.0\n",
    "min_epsilon = 0.01\n",
    "decay_rate = 0.01\n",
    "# List of rewards\n",
    "game1_rewards = []\n",
    "\n",
    "for game1_total_episodes in total_episodes:\n",
    "    episode_total_reward = []\n",
    "    game1_qtable = np.zeros((game1_state_size, game1_action_size))\n",
    "    for episode in range(game1_total_episodes):\n",
    "        state = game1.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "\n",
    "        for step in range(max_steps):\n",
    "            exp_exp_tradeoff = random.uniform(0, 1)\n",
    "\n",
    "            if exp_exp_tradeoff > epsilon:\n",
    "                action = np.argmax(game1_qtable[state, :])\n",
    "            else:\n",
    "                action = game1.action_space.sample()\n",
    "\n",
    "            new_state, reward, done, info = game1.step(action)\n",
    "\n",
    "            game1_qtable[state, action] = game1_qtable[state, action] + learning_rate * (reward + gamma * np.max(game1_qtable[new_state, :]) - game1_qtable[state, action])\n",
    "\n",
    "            total_rewards += reward\n",
    "\n",
    "            state = new_state\n",
    "            if done == True:\n",
    "                break\n",
    "\n",
    "        epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n",
    "        episode_total_reward.append(total_rewards)\n",
    "    game1_rewards.append(episode_total_reward)\n",
    "#     print(\"Score over time: \" + str(sum(game1_rewards)/total_episodes))\n",
    "\n",
    "# plotting\n",
    "order = [[0, 'r'], [1, 'b'], [2, 'g'], [3, 'y']]\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, color in order:\n",
    "    division_ones = np.ones(len(game1_rewards[i]))\n",
    "    plt.plot(np.divide(np.cumsum(game1_rewards[i])[100:], np.cumsum(division_ones)[100:]), color=color)\n",
    "plt.legend([len(game1_rewards[i]) for i in range(4)])\n",
    "plt.title('GAME: FROZEN LAKE, GRAPH: CHANGE IN SCORE WITH NUMBER OF ITERATIONS')\n",
    "plt.xlabel('ITERATION')\n",
    "plt.ylabel('SCORE')\n",
    "plt.savefig('frozenLake_iteration.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Game 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Game 2\n",
    "total_episodes = [25000, 35000, 45000, 50000]\n",
    "learning_rate = 0.9\n",
    "max_steps = 99\n",
    "gamma = 0.618\n",
    "\n",
    "epsilon = 1.0\n",
    "max_epsilon = 1.0\n",
    "min_epsilon = 0.01\n",
    "decay_rate = 0.01\n",
    "# List of rewards\n",
    "game2_rewards = []\n",
    "\n",
    "for game2_total_episodes in total_episodes:\n",
    "    episode_total_reward = []\n",
    "    game2_qtable = np.zeros((game2_state_size, game2_action_size))\n",
    "    for episode in range(game2_total_episodes):\n",
    "        state = game2.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "\n",
    "        for step in range(max_steps):\n",
    "            exp_exp_tradeoff = random.uniform(0, 1)\n",
    "\n",
    "            if exp_exp_tradeoff > epsilon:\n",
    "                action = np.argmax(game2_qtable[state, :])\n",
    "            else:\n",
    "                action = game2.action_space.sample()\n",
    "\n",
    "            new_state, reward, done, info = game2.step(action)\n",
    "\n",
    "            game2_qtable[state, action] = game2_qtable[state, action] + learning_rate * (reward + gamma * np.max(game2_qtable[new_state, :]) - game2_qtable[state, action])\n",
    "\n",
    "            total_rewards += reward\n",
    "\n",
    "            state = new_state\n",
    "            if done == True:\n",
    "                break\n",
    "\n",
    "        epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n",
    "        episode_total_reward.append(total_rewards)\n",
    "    game2_rewards.append(episode_total_reward)\n",
    "    \n",
    "# plotting\n",
    "order = [[0, 'r'], [1, 'b'], [2, 'g'], [3, 'y']]\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, color in order:\n",
    "    division_ones = np.ones(len(game2_rewards[i]))\n",
    "    plt.plot(np.divide(np.cumsum(game2_rewards[i])[100:], np.cumsum(division_ones)[100:]), color=color)\n",
    "plt.legend([len(game2_rewards[i]) for i in range(4)])\n",
    "plt.title('GAME: TAXI, GRAPH: CHANGE IN SCORE WITH NUMBER OF ITERATIONS')\n",
    "plt.xlabel('ITERATION')\n",
    "plt.ylabel('SCORE')\n",
    "plt.savefig('taxi_iteration.png')\n",
    "plt.show()\n",
    "\n",
    "# print(\"Score over time: \" + str(sum(game2_rewards)/total_episodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Game 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Game 1\n",
    "total_episodes = 25000\n",
    "learning_rate = [0.6, 0.7, 0.8, 0.9]\n",
    "max_steps = 99\n",
    "gamma = 0.95\n",
    "\n",
    "epsilon = 1.0\n",
    "max_epsilon = 1.0\n",
    "min_epsilon = 0.01\n",
    "decay_rate = 0.01\n",
    "# List of rewards\n",
    "game1_rewards = []\n",
    "\n",
    "for game1_learning_rate in learning_rate:\n",
    "    rate_total_reward = []\n",
    "    game1_qtable = np.zeros((game1_state_size, game1_action_size))\n",
    "    for episode in range(total_episodes):\n",
    "        state = game1.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "\n",
    "        for step in range(max_steps):\n",
    "            exp_exp_tradeoff = random.uniform(0, 1)\n",
    "\n",
    "            if exp_exp_tradeoff > epsilon:\n",
    "                action = np.argmax(game1_qtable[state, :])\n",
    "            else:\n",
    "                action = game1.action_space.sample()\n",
    "\n",
    "            new_state, reward, done, info = game1.step(action)\n",
    "\n",
    "            game1_qtable[state, action] = game1_qtable[state, action] + game1_learning_rate * (reward + gamma * np.max(game1_qtable[new_state, :]) - game1_qtable[state, action])\n",
    "\n",
    "            total_rewards += reward\n",
    "\n",
    "            state = new_state\n",
    "            if done == True:\n",
    "                break\n",
    "\n",
    "        epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n",
    "        rate_total_reward.append(total_rewards)\n",
    "    game1_rewards.append(rate_total_reward)\n",
    "#     print(\"Score over time: \" + str(sum(game1_rewards)/total_episodes))\n",
    "\n",
    "# plotting\n",
    "order = [[0, 'r'], [1, 'b'], [2, 'g'], [3, 'y']]\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, color in order:\n",
    "    division_ones = np.ones(len(game1_rewards[i]))\n",
    "    plt.plot(np.divide(np.cumsum(game1_rewards[i])[100:], np.cumsum(division_ones)[100:]), color=color)\n",
    "plt.legend(learning_rate)\n",
    "plt.title('GAME: FROZEN LAKE, GRAPH: CHANGE IN SCORE WITH RATE')\n",
    "plt.xlabel('ITERATION')\n",
    "plt.ylabel('SCORE')\n",
    "plt.savefig('frozenLake_rate.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Game 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Game 2\n",
    "total_episodes = 40000\n",
    "learning_rate = [0.6, 0.7, 0.8, 0.9]\n",
    "max_steps = 99\n",
    "gamma = 0.618\n",
    "\n",
    "epsilon = 1.0\n",
    "max_epsilon = 1.0\n",
    "min_epsilon = 0.01\n",
    "decay_rate = 0.01\n",
    "# List of rewards\n",
    "game2_rewards = []\n",
    "\n",
    "for game2_learning_rate in learning_rate:\n",
    "    rate_total_reward = []\n",
    "    game2_qtable = np.zeros((game2_state_size, game2_action_size))\n",
    "    for episode in range(total_episodes):\n",
    "        state = game2.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "\n",
    "        for step in range(max_steps):\n",
    "            exp_exp_tradeoff = random.uniform(0, 1)\n",
    "\n",
    "            if exp_exp_tradeoff > epsilon:\n",
    "                action = np.argmax(game2_qtable[state, :])\n",
    "            else:\n",
    "                action = game2.action_space.sample()\n",
    "\n",
    "            new_state, reward, done, info = game2.step(action)\n",
    "\n",
    "            game2_qtable[state, action] = game2_qtable[state, action] + game2_learning_rate * (reward + gamma * np.max(game2_qtable[new_state, :]) - game2_qtable[state, action])\n",
    "\n",
    "            total_rewards += reward\n",
    "\n",
    "            state = new_state\n",
    "            if done == True:\n",
    "                break\n",
    "\n",
    "        epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n",
    "        rate_total_reward.append(total_rewards)\n",
    "    game2_rewards.append(rate_total_reward)\n",
    "    \n",
    "# plotting\n",
    "order = [[0, 'r'], [1, 'b'], [2, 'g'], [3, 'y']]\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, color in order:\n",
    "    division_ones = np.ones(len(game2_rewards[i]))\n",
    "    plt.plot(np.divide(np.cumsum(game2_rewards[i])[100:], np.cumsum(division_ones)[100:]), color=color)\n",
    "plt.legend(learning_rate)\n",
    "plt.title('GAME: TAXI, GRAPH: CHANGE IN SCORE WITH RATE')\n",
    "plt.xlabel('ITERATION')\n",
    "plt.ylabel('SCORE')\n",
    "plt.savefig('taxi_rate.png')\n",
    "plt.show()\n",
    "\n",
    "# print(\"Score over time: \" + str(sum(game2_rewards)/total_episodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Game 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Game 1\n",
    "total_episodes = 25000\n",
    "learning_rate = 0.9\n",
    "max_steps = 99\n",
    "gamma = [0.80, 0.85, 0.90, 0.95]\n",
    "\n",
    "epsilon = 1.0\n",
    "max_epsilon = 1.0\n",
    "min_epsilon = 0.01\n",
    "decay_rate = 0.01\n",
    "# List of rewards\n",
    "game1_rewards = []\n",
    "\n",
    "for game1_gamma in gamma:\n",
    "    gamma_total_reward = []\n",
    "    game1_qtable = np.zeros((game1_state_size, game1_action_size))\n",
    "    for episode in range(total_episodes):\n",
    "        state = game1.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "\n",
    "        for step in range(max_steps):\n",
    "            exp_exp_tradeoff = random.uniform(0, 1)\n",
    "\n",
    "            if exp_exp_tradeoff > epsilon:\n",
    "                action = np.argmax(game1_qtable[state, :])\n",
    "            else:\n",
    "                action = game1.action_space.sample()\n",
    "\n",
    "            new_state, reward, done, info = game1.step(action)\n",
    "\n",
    "            game1_qtable[state, action] = game1_qtable[state, action] + learning_rate * (reward + game1_gamma * np.max(game1_qtable[new_state, :]) - game1_qtable[state, action])\n",
    "\n",
    "            total_rewards += reward\n",
    "\n",
    "            state = new_state\n",
    "            if done == True:\n",
    "                break\n",
    "\n",
    "        epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n",
    "        gamma_total_reward.append(total_rewards)\n",
    "    game1_rewards.append(gamma_total_reward)\n",
    "#     print(\"Score over time: \" + str(sum(game1_rewards)/total_episodes))\n",
    "\n",
    "# plotting\n",
    "order = [[0, 'r'], [1, 'b'], [2, 'g'], [3, 'y']]\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, color in order:\n",
    "    division_ones = np.ones(len(game1_rewards[i]))\n",
    "    plt.plot(np.divide(np.cumsum(game1_rewards[i])[100:], np.cumsum(division_ones)[100:]), color=color)\n",
    "plt.legend(gamma)\n",
    "plt.title('GAME: FROZEN LAKE, GRAPH: CHANGE IN SCORE WITH GAMMA')\n",
    "plt.xlabel('ITERATION')\n",
    "plt.ylabel('SCORE')\n",
    "plt.savefig('frozenLake_gamma.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Game 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Game 2\n",
    "total_episodes = 40000\n",
    "learning_rate = 0.9\n",
    "max_steps = 99\n",
    "gamma = [0.6, 0.618, 0.7, 0.8]\n",
    "\n",
    "epsilon = 1.0\n",
    "max_epsilon = 1.0\n",
    "min_epsilon = 0.01\n",
    "decay_rate = 0.01\n",
    "# List of rewards\n",
    "game2_rewards = []\n",
    "\n",
    "for game2_gamma in gamma:\n",
    "    gamma_total_reward = []\n",
    "    game2_qtable = np.zeros((game2_state_size, game2_action_size))\n",
    "    for episode in range(game2_total_episodes):\n",
    "        state = game2.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "\n",
    "        for step in range(max_steps):\n",
    "            exp_exp_tradeoff = random.uniform(0, 1)\n",
    "\n",
    "            if exp_exp_tradeoff > epsilon:\n",
    "                action = np.argmax(game2_qtable[state, :])\n",
    "            else:\n",
    "                action = game2.action_space.sample()\n",
    "\n",
    "            new_state, reward, done, info = game2.step(action)\n",
    "\n",
    "            game2_qtable[state, action] = game2_qtable[state, action] + learning_rate * (reward + game2_gamma * np.max(game2_qtable[new_state, :]) - game2_qtable[state, action])\n",
    "\n",
    "            total_rewards += reward\n",
    "\n",
    "            state = new_state\n",
    "            if done == True:\n",
    "                break\n",
    "\n",
    "        epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n",
    "        gamma_total_reward.append(total_rewards)\n",
    "    game2_rewards.append(gamma_total_reward)\n",
    "    \n",
    "# plotting\n",
    "order = [[0, 'r'], [1, 'b'], [2, 'g'], [3, 'y']]\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, color in order:\n",
    "    division_ones = np.ones(len(game2_rewards[i]))\n",
    "    plt.plot(np.divide(np.cumsum(game2_rewards[i])[100:], np.cumsum(division_ones)[100:]), color=color)\n",
    "plt.legend(gamma)\n",
    "plt.title('GAME: TAXI, GRAPH: CHANGE IN SCORE WITH GAMMA')\n",
    "plt.xlabel('ITERATION')\n",
    "plt.ylabel('SCORE')\n",
    "plt.savefig('taxi_gamma.png')\n",
    "plt.show()\n",
    "\n",
    "# print(\"Score over time: \" + str(sum(game2_rewards)/total_episodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decay Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Game 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Game 1\n",
    "total_episodes = 25000\n",
    "learning_rate = 0.9\n",
    "max_steps = 99\n",
    "gamma = 0.95\n",
    "\n",
    "epsilon = 1.0\n",
    "max_epsilon = 1.0\n",
    "min_epsilon = 0.01\n",
    "decay_rate = [0.1, 0.05, 0.01, 0.001]\n",
    "# List of rewards\n",
    "game1_rewards = []\n",
    "\n",
    "for game1_decay_rate in decay_rate:\n",
    "    decay_rate_total_reward = []\n",
    "    game1_qtable = np.zeros((game1_state_size, game1_action_size))\n",
    "    for episode in range(total_episodes):\n",
    "        state = game1.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "\n",
    "        for step in range(max_steps):\n",
    "            exp_exp_tradeoff = random.uniform(0, 1)\n",
    "\n",
    "            if exp_exp_tradeoff > epsilon:\n",
    "                action = np.argmax(game1_qtable[state, :])\n",
    "            else:\n",
    "                action = game1.action_space.sample()\n",
    "\n",
    "            new_state, reward, done, info = game1.step(action)\n",
    "\n",
    "            game1_qtable[state, action] = game1_qtable[state, action] + learning_rate * (reward + gamma * np.max(game1_qtable[new_state, :]) - game1_qtable[state, action])\n",
    "\n",
    "            total_rewards += reward\n",
    "\n",
    "            state = new_state\n",
    "            if done == True:\n",
    "                break\n",
    "\n",
    "        epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-game1_decay_rate*episode)\n",
    "        decay_rate_total_reward.append(total_rewards)\n",
    "    game1_rewards.append(decay_rate_total_reward)\n",
    "#     print(\"Score over time: \" + str(sum(game1_rewards)/total_episodes))\n",
    "\n",
    "# plotting\n",
    "order = [[0, 'r'], [1, 'b'], [2, 'g'], [3, 'y']]\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, color in order:\n",
    "    division_ones = np.ones(len(game1_rewards[i]))\n",
    "    plt.plot(np.divide(np.cumsum(game1_rewards[i])[100:], np.cumsum(division_ones)[100:]), color=color)\n",
    "plt.legend(decay_rate)\n",
    "plt.title('GAME: FROZEN LAKE, GRAPH: CHANGE IN SCORE WITH DECAY RATE')\n",
    "plt.xlabel('ITERATION')\n",
    "plt.ylabel('SCORE')\n",
    "plt.savefig('frozenLake_decay_rate.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Game 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Game 1\n",
    "total_episodes = 25000\n",
    "learning_rate = 0.9\n",
    "max_steps = 99\n",
    "gamma = 0.95\n",
    "\n",
    "epsilon = 1.0\n",
    "max_epsilon = 1.0\n",
    "min_epsilon = 0.01\n",
    "decay_rate = [0.1, 0.05, 0.01, 0.001]\n",
    "# List of rewards\n",
    "game1_rewards = []\n",
    "\n",
    "for game2_decay_rate in decay_rate:\n",
    "    decay_rate_total_reward = []\n",
    "    game2_qtable = np.zeros((game2_state_size, game2_action_size))\n",
    "    for episode in range(total_episodes):\n",
    "        state = game2.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "\n",
    "        for step in range(max_steps):\n",
    "            exp_exp_tradeoff = random.uniform(0, 1)\n",
    "\n",
    "            if exp_exp_tradeoff > epsilon:\n",
    "                action = np.argmax(game2_qtable[state, :])\n",
    "            else:\n",
    "                action = game2.action_space.sample()\n",
    "\n",
    "            new_state, reward, done, info = game2.step(action)\n",
    "\n",
    "            game2_qtable[state, action] = game2_qtable[state, action] + learning_rate * (reward + gamma * np.max(game2_qtable[new_state, :]) - game2_qtable[state, action])\n",
    "\n",
    "            total_rewards += reward\n",
    "\n",
    "            state = new_state\n",
    "            if done == True:\n",
    "                break\n",
    "\n",
    "        epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-game2_decay_rate*episode)\n",
    "        decay_rate_total_reward.append(total_rewards)\n",
    "    game2_rewards.append(decay_rate_total_reward)\n",
    "#     print(\"Score over time: \" + str(sum(game1_rewards)/total_episodes))\n",
    "\n",
    "# plotting\n",
    "order = [[0, 'r'], [1, 'b'], [2, 'g'], [3, 'y']]\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, color in order:\n",
    "    division_ones = np.ones(len(game2_rewards[i]))\n",
    "    plt.plot(np.divide(np.cumsum(game2_rewards[i])[100:], np.cumsum(division_ones)[100:]), color=color)\n",
    "plt.legend(decay_rate)\n",
    "plt.title('GAME: FROZEN LAKE, GRAPH: CHANGE IN SCORE WITH DECAY RATE')\n",
    "plt.xlabel('ITERATION')\n",
    "plt.ylabel('SCORE')\n",
    "plt.savefig('taxi_decay_rate.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
